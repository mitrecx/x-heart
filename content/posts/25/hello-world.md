+++
date = '2025-07-02T17:20:41+08:00'
draft = false
title = 'Hello World'
categories = ["技术分享"]
tags = ["RAG", "AI", "机器学习"]
ShowBreadCrumbs = false
+++

RAG，全称是 Retrieval-Augmented Generation（检索增强生成），是一种结合外部知识检索和语言模型生成能力的方法，用来提升问答或生成任务的效果，尤其在处理知识密集型任务（如文档问答、企业知识库问答）时非常有效。

⸻

🧠 为什么需要 RAG？

大语言模型（如 GPT-4）虽然很强大，但它有两个主要问题：
	1.	知识受限：模型训练是静态的，无法了解最新信息或用户私有知识。
	2.	幻觉问题（hallucination）：模型有时会“编造”看起来合理但实际错误的信息。

RAG 的目标就是解决这两个问题 ——
👉 “用外部真实数据来增强语言模型的回答能力。”

⸻

🔁 RAG 的工作流程（两阶段）：

步骤 1：Retrieval（检索）

从大量文档中（如 PDF、网页、数据库）检索出与问题相关的内容。
	•	文档被分割成小块（chunk）
	•	每个块被转换成向量（embedding）
	•	根据用户问题，计算相似度，取出相关文段

步骤 2：Generation（生成）

将用户问题 + 检索到的相关文段拼接成 prompt，交给语言模型生成答案。

⸻

📌 示例

用户问题：

“ChatGPT 是谁开发的？”

系统内部处理：
	1.	检索阶段：
	•	从文档中找到片段：“ChatGPT 是由 OpenAI 开发的，是一种基于 GPT 架构的聊天机器人。”
	2.	生成阶段：
	•	模型接收到 prompt：

根据以下信息回答问题：
信息：ChatGPT 是由 OpenAI 开发的，是一种基于 GPT 架构的聊天机器人。
问题：ChatGPT 是谁开发的？


	•	生成回答：“ChatGPT 是由 OpenAI 开发的。”

⸻

✅ RAG 的优势

优点	说明
📚 可用私有文档	能加载自己公司的文档、知识库
🔄 动态知识更新	不需要重训模型，只需更新文档
🧠 更少幻觉	有依据地回答问题
🎯 精准问答	适合构建文档问答系统、智能客服等


⸻

🛠 RAG 常用工具和框架

工具 / 框架	作用
LangChain	构建 RAG 工作流（文档加载、分块、嵌入、检索、生成）
LlamaIndex	强调索引和检索能力，RAG 优化
FAISS / Chroma	向量数据库，用于高效相似度检索
OpenAI Embedding	把文本转换成向量
BGE, MiniLM 等	本地开源 embedding 模型，适合私有部署


⸻

🧱 RAG 架构图（简化版）

用户问题 --> 向量化 --> 在向量数据库中检索 --> 得到相关文档
        ↓                                          ↑
        +-----------> 拼接 prompt 给大模型 --------+
                          ↓
                   模型输出最终答案


⸻

🔍 应用场景
	•	企业文档问答系统
	•	PDF / Word / 知识库聊天机器人
	•	医疗、金融、法律等领域的智能问答
	•	编程问答（给代码片段生成解释）

⸻

如你需要，我可以帮你写一个完整的 RAG 示例程序，比如“ChatPDF”那种模型。如果你提供自己的文档，我还可以教你怎么用 LangChain + RAG 在本地搭一个问答系统。需要吗？